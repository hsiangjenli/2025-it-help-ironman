# ä»‹ç´¹

# ä½¿ç”¨ Ollama ä»¥åŠ LangGraph å¯¦ä½œ Agent Server

æœ¬æ¬¡ä½¿ç”¨ [`a2aproject/a2a-samples`](https://github.com/a2aproject/a2a-samples) ä¸­çš„ LangGraph ç¯„ä¾‹ä¾†ç¤ºç¯„ä¾†æ“ä½œå¦‚å’Œä½¿ç”¨ Ollama ä½œçˆ² LLM backend ä¸¦ä¸”çµåˆ `a2a-sdk` ä¾†å¯¦ä½œä¸€å€‹ç°¡å–®çš„ Agent Serverã€‚

## ä¸‹è¼‰ç¯„ä¾‹ç¨‹å¼ç¢¼ + æº–å‚™ç’°å¢ƒ

```shell
git clone https://github.com/a2aproject/a2a-samples.git
cd a2a-samples/samples/python/agents/langgraph
uv sync
```

## æ¶æ§‹ä»‹ç´¹

```shell
app/
â”œâ”€â”€ __init__.py         
â”œâ”€â”€ __main__.py # ä¸»ç¨‹å¼ï¼Œå•Ÿå‹• A2A ä¼ºæœå™¨       
â”œâ”€â”€ agent.py # æ ¸å¿ƒ AI Agentï¼ˆä½¿ç”¨ LangGraphï¼‰
â”œâ”€â”€ agent_executor.py # Agent Executorï¼Œè² è²¬ç®¡ç†æ•´å€‹ Agent çš„ç”Ÿå‘½é€±æœŸ
â””â”€â”€ test_client.py 
```

- `agent.py`ï¼šå®šç¾© Agent çš„è¡Œçˆ²ï¼Œé€™é‚Šä½¿ç”¨ LangGraph ä¾†å¯¦ä½œ
- `agent_executor.py`ï¼šå®šç¾© Agent Executorï¼Œè² è²¬ç®¡ç†æ•´å€‹ Agent çš„ç”Ÿå‘½é€±æœŸ

### `agent.py`

- å»ºç«‹ä¸€å€‹ LangGraph Agent çš„å¯¦ä¾‹ï¼ˆ`CurrencyAgent`ï¼‰

### `agent_executor.py`

```python
class AgentExecutor(ABC):
    """Agent Executor interface.

    Implementations of this interface contain the core logic of the agent,
    executing tasks based on requests and publishing updates to an event queue.
    """

    @abstractmethod
    async def execute(
        self, context: RequestContext, event_queue: EventQueue
    ) -> None:
        """Execute the agent's logic for a given request context.

        The agent should read necessary information from the `context` and
        publish `Task` or `Message` events, or `TaskStatusUpdateEvent` /
        `TaskArtifactUpdateEvent` to the `event_queue`. This method should
        return once the agent's execution for this request is complete or
        yields control (e.g., enters an input-required state).

        Args:
            context: The request context containing the message, task ID, etc.
            event_queue: The queue to publish events to.
        """

    @abstractmethod
    async def cancel(
        self, context: RequestContext, event_queue: EventQueue
    ) -> None:
        """Request the agent to cancel an ongoing task.

        The agent should attempt to stop the task identified by the task_id
        in the context and publish a `TaskStatusUpdateEvent` with state
        `TaskState.canceled` to the `event_queue`.

        Args:
            context: The request context containing the task ID to cancel.
            event_queue: The queue to publish the cancellation status update to.
        """
```

- ä¸€å€‹ Agent Executor çš„ä»‹é¢ï¼Œéœ€è¦å¯¦ä½œ `execute` ä»¥åŠ `cancel` æ–¹æ³•

```python
    async def execute(
        self,
        context: RequestContext,
        event_queue: EventQueue,
    ) -> None:
        error = self._validate_request(context)
        if error:
            raise ServerError(error=InvalidParamsError())

        query = context.get_user_input()
        task = context.current_task
        if not task:
            task = new_task(context.message)  # â­ (1) å»ºç«‹ä¸€å€‹æ–°çš„ Task
            await event_queue.enqueue_event(task) # â­ (2) ç™¼å¸ƒåˆ°äº‹ä»¶ä½‡åˆ—
        updater = TaskUpdater(event_queue, task.id, task.context_id) # â­ (3) å»ºç«‹ä¸€å€‹ TaskUpdater ä¾†æ›´æ–° Task ç‹€æ…‹
        try:
            # â­ (4) è™•ç†éç¨‹ä¸­æœƒæŒçºŒçš„ stream response
            async for item in self.agent.stream(query, task.context_id):
                is_task_complete = item['is_task_complete']
                require_user_input = item['require_user_input']

                if not is_task_complete and not require_user_input:
                    await updater.update_status(
                        TaskState.working,
                        new_agent_text_message(
                            item['content'],
                            task.context_id,
                            task.id,
                        ),
                    )
                elif require_user_input:
                    await updater.update_status(
                        TaskState.input_required,
                        new_agent_text_message(
                            item['content'],
                            task.context_id,
                            task.id,
                        ),
                        final=True,
                    )
                    break
                else:
                    await updater.add_artifact(
                        [Part(root=TextPart(text=item['content']))],
                        name='conversion_result',
                    )
                    await updater.complete()
                    break

        except Exception as e:
            logger.error(f'An error occurred while streaming the response: {e}')
            raise ServerError(error=InternalError()) from e
```

## èª¿æ•´è¨­å®š

### ä¿®æ”¹ç’°å¢ƒè®Šæ•¸

å»ºç«‹ `.env` æª”æ¡ˆï¼Œè¨­å®šä½¿ç”¨ Ollamaï¼š

```shell
# .env
model_source=ollama
API_KEY=your_api_key_here
TOOL_LLM_URL=http://localhost:11434/api/chat
TOOL_LLM_NAME=llama3.2:3b
```

### ç¨‹å¼ç¢¼èª¿æ•´ (å¯é¸)

å¦‚æœè¦å®Œå…¨ç§»é™¤ Google API æª¢æŸ¥ï¼Œå¯ä»¥è¨»è§£æ‰ä»¥ä¸‹ç¨‹å¼ç¢¼ï¼š

```python
# åœ¨ __main__.py ä¸­è¨»è§£æ‰
# if not os.getenv('GOOGLE_API_KEY'):
#     raise MissingAPIKeyError(
#         'GOOGLE_API_KEY environment variable not set.'
#     )
```

### ç¢ºèª Ollama è¨­å®š

```shell
# ç¢ºèª Ollama æœå‹™é‹è¡Œ
ollama list

# å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œä¸‹è¼‰æ¨¡å‹
ollama pull llama3.2:3b

# æ¸¬è©¦æ¨¡å‹å›æ‡‰
ollama run llama3.2:3b "Hello, how are you?"
```

## å•“å‹• Agent Server

```shell
uv run app
```
å¯ä»¥åœ¨ [http://localhost:10000/.well-known/agent.json](http://localhost:10000/.well-known/agent.json) çœ‹åˆ° Agent Card

![20250923203324](https://raw.githubusercontent.com/hsiangjenli/pic-bed/main/images/20250923203324.png)

## æ¸¬è©¦ Agent Server

```shell
# æ¸¬è©¦ Agent Server

## 1. æ¸¬è©¦ Ollama API é€£ç·š

é¦–å…ˆç¢ºèª Ollama æœå‹™æ­£å¸¸é‹ä½œï¼š

```shell
# æ¸¬è©¦ ollama API
curl -X POST http://localhost:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.2:3b",
    "messages": [
      {
        "role": "user",
        "content": "Hello"
      }
    ]
  }'
```

![20250923200419](https://raw.githubusercontent.com/hsiangjenli/pic-bed/main/images/20250923200419.png)

## 2. æ¸¬è©¦ A2A Agent Server

### ä½¿ç”¨å…§å»ºæ¸¬è©¦å®¢æˆ¶ç«¯

```shell
uv run app/test_client.py
```

### ä½¿ç”¨ curl æ¸¬è©¦åŒæ­¥è«‹æ±‚

```shell
curl -X POST http://localhost:10000 \
  -H "Content-Type: application/json" \
  -d '{
    "id": "12113c25-b752-473f-977e-c9ad33cf4f56",
    "jsonrpc": "2.0",
    "method": "message/send",
    "params": {
        "message": {
            "kind": "message",
            "messageId": "120ec73f93024993becf954d03a672bc",
            "parts": [
                {
                    "kind": "text",
                    "text": "how much is 10 USD in INR?"
                }
            ],
            "role": "user"
        }
    }
}'
```

## 3. å•é¡Œæ’é™¤

### å¸¸è¦‹éŒ¯èª¤å’Œè§£æ±ºæ–¹æ¡ˆ

1. **Internal error (-32603)**:
   - æª¢æŸ¥ Ollama æœå‹™æ˜¯å¦é‹è¡Œï¼š`ollama list`
   - ç¢ºèªæ¨¡å‹å·²ä¸‹è¼‰ï¼š`ollama pull llama3.2:3b`
   - æª¢æŸ¥ `.env` æª”æ¡ˆè¨­å®š

2. **é€£ç·šéŒ¯èª¤**:
   - ç¢ºèª Ollama API åœ¨ `http://localhost:11434` é‹è¡Œ
   - æ¸¬è©¦ Ollama API é€£ç·šï¼ˆå¦‚ä¸Šé¢çš„æ¸¬è©¦ï¼‰

3. **æ¨¡å‹ä¸å­˜åœ¨**:
   ```shell
   ollama pull llama3.2:3b
   ollama list | grep llama3.2
   ```
```

![20250923200419](https://raw.githubusercontent.com/hsiangjenli/pic-bed/main/images/20250923200419.png)

# é‡é»å›é¡§

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

1. **A2A å”è­°**: Agent-to-Agent é€šè¨Šå”è­°ï¼Œæ¨™æº–åŒ– AI ä»£ç†é–“çš„äº’å‹•
2. **äº‹ä»¶é©…å‹•æ¶æ§‹**: ä½¿ç”¨äº‹ä»¶ä½‡åˆ— (EventQueue) è€Œéç›´æ¥å›å‚³çµæœ
3. **åˆ†å±¤è¨­è¨ˆ**: 
   - `agent.py`: ç´” AI é‚è¼¯å±¤
   - `agent_executor.py`: å”è­°é©é…å±¤
   - `__main__.py`: ä¼ºæœå™¨å•Ÿå‹•å±¤

## ğŸ”§ æŠ€è¡“è¦é»

### Agent Executor è¨­è¨ˆæ¨¡å¼
- **`execute` æ–¹æ³•**: ä¸å›å‚³å€¼ï¼Œé€éäº‹ä»¶ä½‡åˆ—ç™¼å¸ƒçµæœ
- **ä»»å‹™ç”Ÿå‘½é€±æœŸ**: `working` â†’ `input_required`/`completed`
- **ä¸²æµè™•ç†**: å³æ™‚æ›´æ–°ä»»å‹™ç‹€æ…‹

### Ollama æ•´åˆ
- **æ¨¡å‹é¸æ“‡**: æ”¯æ´å¤šç¨®æœ¬åœ° LLM
- **API çµ±ä¸€**: ä½¿ç”¨ OpenAI ç›¸å®¹çš„ API æ ¼å¼
- **ç„¡éœ€å¤–éƒ¨ API**: å®Œå…¨æœ¬åœ°åŒ–éƒ¨ç½²

## ğŸ’¡ å­¸ç¿’æ”¶ç©«

1. **äº‹ä»¶é©…å‹• vs å‚³çµ±è«‹æ±‚å›æ‡‰**: æ›´é©åˆé•·æ™‚é–“é‹è¡Œçš„ AI ä»»å‹™
2. **å”è­°æŠ½è±¡**: å°‡æ¥­å‹™é‚è¼¯èˆ‡é€šè¨Šå”è­°åˆ†é›¢
3. **æœ¬åœ° LLM éƒ¨ç½²**: åœ¨åœ°åŒ– AI æœå‹™çš„å¯¦å‹™æ‡‰ç”¨

## ğŸ“ˆ æ“´å±•å¯èƒ½

- æ”¯æ´å¤šæ¨¡æ…‹è¼¸å…¥ (åœ–ç‰‡ã€éŸ³è¨Š)
- å¯¦ä½œä»»å‹™å–æ¶ˆåŠŸèƒ½
- æ·»åŠ æ›´å¤šå·¥å…·å’Œ API æ•´åˆ
- å¯¦ä½œæŒä¹…åŒ–è¨˜æ†¶å­˜å„²

# åƒè€ƒè³‡æ–™

## ğŸ”— å®˜æ–¹è³‡æº

- [A2A Project GitHub](https://github.com/a2aproject/a2a-samples) - A2A å”è­°ç¯„ä¾‹å°ˆæ¡ˆ
- [LangGraph å®˜æ–¹æ–‡ä»¶](https://langchain-ai.github.io/langgraph/) - LangGraph æ¡†æ¶æ–‡ä»¶
- [Ollama å®˜æ–¹ç¶²ç«™](https://ollama.ai/) - æœ¬åœ° LLM é‹è¡Œå¹³å°

## ğŸ“š ç›¸é—œæŠ€è¡“æ–‡ä»¶

- [A2A Protocol Specification](https://a2aproject.org/) - A2A å”è­°è¦ç¯„
- [Frankfurter API](https://www.frankfurter.app/) - åŒ¯ç‡æŸ¥è©¢ API
- [FastAPI Documentation](https://fastapi.tiangolo.com/) - Web API æ¡†æ¶
- [Pydantic](https://pydantic-docs.helpmanual.io/) - è³‡æ–™é©—è­‰åº«

## ğŸ› ï¸ é–‹ç™¼å·¥å…·

- [uv](https://github.com/astral-sh/uv) - Python å¥—ä»¶ç®¡ç†å·¥å…·
- [Uvicorn](https://www.uvicorn.org/) - ASGI ä¼ºæœå™¨
- [httpx](https://www.python-httpx.org/) - HTTP å®¢æˆ¶ç«¯åº«