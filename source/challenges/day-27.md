# 【Day27】介紹 OWASP LLM Top 10

## 介紹

把 OWASP LLM Top 10 2025 的十個風險一個一個看完，目的是先了解有哪些風險以及這些風險的防禦方法，後續可以針對這些防範方法進行實作。

## 2025 年 LLM 與生成式 AI 應用的十大風險與因應措施

共通模版：

```markdown
- **風險描述**：解釋這個風險是什麼
- **防禦策略**：可以採取哪些策略或防線，來降低此風險發生或影響的可能性
```

### LLM01:2025 Prompt Injection

#### 風險描述
攻擊者透過內容（文字、圖片等資料）修改或是覆蓋掉原本的上下文或是系統指令，導致 LLM 產生非預期輸出（錯誤、惡意）、泄露出敏感資訊、執行未授權的操作

#### 防禦策略
- **限制模型行為**：在 System Prompt 中規定模型角色，要求上下文一致、限制輸出、指式 AI 忽略忽略試圖修改指令的輸入
- **明確的輸出格式**：針對輸出進行 Validation
- **輸入輸出過濾**：建立偵測規則（類別），針對「語意」、「文字」進行檢查或是可以採用「RAG Triad」來判斷潛在惡意輸出
- **最小權限與權限控管**：只給模型完成任務所需的功能（例如僅允許讀取而非新增刪除），並依操作風險分級：低風險自動執行、中風險有限制、高風險才需人工審核。
- **人機協作**：在風險較高的場景需要人工審查
- **標記內容來源**：將可信、不可信的資料來源進行標記，限制提示的影響力
- **進行對抗性測試跟攻擊模擬**：定期測試，將模型視為不可信使用者，以檢驗信任邊界、存取控制與安全機制的有效性

### LLM02:2025 Sensitive Information Disclosure

#### 風險描述
LLM 在處理或生成回應時，可能會意外洩露敏感資訊（個人、公司內部機密演算法）

#### 防禦策略
- **資料清理**：資料在進入訓練前，進行清洗或遮蔽敏感內容
- **輸入驗證**：偵測、過濾潛在有害或敏感的輸入
- **最小權限原則**：限制對敏感資料的存取，僅授權必要使用者或流程
- **限制資料來源**：控制模型可存取的資料來源（外部資料，可能包含惡意、敏感內容）
- **聯邦學習**：將訓練分散在多個伺服器或設備，減少集中蒐集資料的需求與風險
- **差分隱私**：在資料或輸出中加入噪音，使攻擊者難以還原個別數據
- **同態加密**：在加密態下進行運算的技術，讓資料在處理過程中仍保持機密性
- **標記化與遮蔽**：前處理階段辨識敏感字串、進行遮蔽或標記，防止資訊被納入模型訓練過程中
- **隱藏系統提示**：禁止讓使用者讀取到系統提示
- **安全錯誤處理**：LLM 應用後端在處理 request 時，避免將產生的錯誤輸出給使用者
- **教育使用者**：避免用戶輸入敏感資訊
- **定義明確的資料使用規則**：制定清楚的資料保留、使用與刪除政策，並允許使用者選擇退出被納入訓練過程

### LLM03:2025 Supply Chain

#### 風險描述
LLM 的整個供應鏈中產生的漏洞可能會損害訓練資料、模型和部署平台的完整性。進而導致偏頗的輸出、安全性漏洞。與傳統軟體漏洞類似，發生在程式的相依套件中，甚至會延伸到第三方的預訓練模型與資料

#### 防禦策略
- **資料來源與供應商審查**：嚴格檢查所有資料來源與供應商的可信度，包含使用條款與隱私政策，確保不會因政策變更而引入新風險
- **漏洞與過時元件管理**：採用 OWASP A06:2021 – Vulnerable and Outdated Components，執行漏洞掃描、修補與套件管理，並在含有敏感資料的環境中同樣實施
- **AI 紅隊與安全評估**：在選用第三方模型前進行演練與評估，例如模擬攻擊、對抗測試，確認模型在實際應用場景中的安全性
- **軟體物料清單**：建立 AI BOM /ML SBOM，確保清單完整且具備簽章，能及時偵測零日漏洞與避免供應鏈被竄改
- **授權管理**：建立完整的授權清單，定期稽核所有軟體、工具與資料集的授權狀況
- **異常檢測與對抗性測試**：在 MLOps 與 LLM pipeline 中內建異常檢測與對抗性魯棒性測試，以便及早發現資料或模型遭到竄改與投毒
- **修補政策**：定期更新過時或脆弱的元件
- **完整性檢查**：僅使用來源可驗證的模型，透過簽章與檔案雜湊檢查完整性；部署時，對模型進行加密並啟用完整性檢查與供應商驗證機制，防止模型或應用被竄改或替換

### LLM04:2025 Data and Model Poisoning

#### 風險描述
在預訓練（pre-training）、微調（fine-tuning）或嵌入（embedding）資料階段遭到惡意操縱，進而引入弱點、後門或偏見

#### 防禦策略
- **追蹤資料來源與轉換**：使用 OWASP CycloneDX 或 ML-BOM 追蹤資料來源與轉換過程，確認模型在各個開發階段的資料合法性
- **嚴格審查供應商**：針對模型輸出結果進行
- **實施沙箱機制**：
- **基礎設施管控**：避免模型存取未授權的資料來源
- **資料版本控制**：追蹤資料集的變動，偵測是否被操縱
- **避免訓練模型**：盡量使用向量資料庫，避免重新訓練整個模型
- **紅隊演練與對抗測試**：模擬攻擊場景來測試模型韌性，降低遭受資料投毒或對抗攻擊的風險
- **監控訓練過程**：持續監控訓練損失與模型行為，透過閾值檢測異常，及早發現投毒跡象
- **整合 RAG 與 Grounding**：RAG 可以提供模型上下文、Grounding 是要求模型輸出時要給出參考資料

### LLM05:2025 Improper Output Handling

#### 風險描述

過度信任 LLM 的輸出，若未經過適當驗證或過濾就直接使用，導致錯誤決策

#### 防禦策略
- **零信任原則**：將模型視為任何其他使用者，針對模型輸出進行驗證
- **OWASP ASVS**：參考 OWASP ASVS 針對輸入進行清理與驗證
- **輸出編碼**：回傳給使用者的模型輸出進行編碼，避免內容被當作程式碼執行
- **內容安全政策**：採用嚴格的 Content Security Policies，降低 XSS 攻擊風險
- **日誌與監控**：記錄模型輸出與使用情況，偵測異常行為

### LLM06:2025 Excessive Agency

#### 風險描述
給予 LLM 過多的自主權，導致其執行未經授權的操作或做出不當決策

#### 防禦策略
- **最小化原則**：限制 LLM 可使用的外部工具與 API，僅允許必要的功能
- **人機協作**：在執行前需要人的核准

### LLM07:2025 System Prompt Leakage

#### 風險描述
系統提示的目的是去引導模型輸出以符合應用需求，但它同時可能不小心放入機密或敏感資料。一旦被發現，這些資訊就可能被用來促成其他攻擊

#### 防禦策略
- **把敏感資料與系統提示分離**：避免在系統提示中放入敏感資訊，將這類資訊外部化，存放在模型無法直接存取的安全系統
- **避免完全依賴系統提示**：不要把行為控制完全依賴系統提示，像是有害內容偵測或敏感請求的阻擋，可以額外透過其它機制來進行過濾
- **外部防護機制**：在系統提示之外，建立額外的防護機制來過濾或審查輸入與輸出

### LLM08:2025 Vector and Embedding Weaknesses

#### 風險描述

若 Embedding 缺乏妥善的存取控制與資料管理，可能導致敏感資訊外洩、跨租戶情境下的知識洩露與衝突；同時存在嵌入反推、資料投毒等攻擊風險，不僅危及資料完整性與機密性，也可能改變模型的原始行為

#### 防禦策略
- **權限與存取控制**：確保不同使用者或群組之間的資料是隔離的。向量資料庫必須能針對每個人、每個群組設定清楚的權限，避免某人查詢時誤拿到不該看的嵌入或敏感資訊
- **資料驗證與來源認證**：資料放進知識庫前，要先確認來源可信，並檢查內容是否有隱藏惡意資訊，同時要定期檢查資料庫，確保裡面的資料沒有被竄改
- **監控與日誌**：所有檢索與查詢記錄都要有完整、不可竄改的紀錄，一旦有可疑的存取行為或攻擊，就能快速追蹤並處理

### LLM09:2025 Misinformation

#### 風險描述
LLM 非常容易產生錯誤的資訊，這些輸出表面可信卻可能完全沒有根據，若使用者過度依賴而未驗證，便可能在決策、法律、醫療或軟體開發中引入嚴重風險，造成資安漏洞、聲譽受損甚至法律責任。例如：攻擊者發現 LLM 經常產出特定的「幻覺套件名稱」，攻擊者就可以利用這點上傳惡意套件至開源庫，導致開發者無意中安裝，進而被植入後門或惡意程式碼

#### 防禦策略
- **檢索增強生成**：在回應生成過程中，從可信的外部資料庫檢索相關資訊
- **模型微調**：透過微調或嵌入向量改善模型輸出品質，降低錯誤資訊
- **交叉驗證與人工審核**：將 LLM 輸出與可信來源交叉比對。對於關鍵或敏感資訊，須要有人類審核，避免過度依賴
- **自動驗證機制**：建立自動化系統來驗證 LLM 的輸出
- **風險溝通**：向使用者清楚說明 LLM 可能產生錯誤資訊的風險
- **安全程式開發實踐**：建立安全的開發流程，確保在設計、開發、測試與部署階段都考慮到安全性
- **使用者介面設計**：在使用者介面中設計防範措施，例如：內容過濾、標示為 AI 生成的內容等
- **教育與訓練**：教育使用者了解 LLM 的限制與風險，以及對其輸出保持批判性思維

### LLM10:2025 Unbounded Consumption

#### 風險描述

#### 防禦策略
- **輸入驗證**：嚴格限制輸入大小，避免超出合理範圍
- **限制 Logits 與 Logprobs 曝露**：因為這些原始分數包含比最終輸出更細節的資訊，若完整公開可能被濫用，攻擊者可以透過大量輸入與對應的 logits 蒐集資料，進行模型抽取，近似重建或複製模型，或是攻擊者可能利用 logits 的微小差異推斷出原本不該洩露的內部資訊或機密
- **速率限制**：限制與使用者配額，限制單一來源在特定時間內的請求數量
- **沙箱技術**：限制 LLM 存取網路資源、內部服務與 API，以降低濫用風險
- **完整的日誌、監控與異常偵測**：記錄所有請求與回應，偵測異常行為
- **浮水印**：在生成的內容中加入浮水印，便於追蹤與識別濫用行為
- **集中化模型清冊**：對生產中使用的模型進行集中管理，確保治理與存取受到控管
- **自動化 MLOps 部署**：使用自動化的 Pipeline，結合治理、追蹤與審批流程，加強基礎設施的存取與部署控制

## 重點回顧
- 讀過 2025 年 LLM 與生成式 AI 應用的十大風險
- 了解各項風險的防禦策略

## 參考資料

- [2025 Top 10 Risk & Mitigations for LLMs and Gen AI Apps](https://genai.owasp.org/llm-top-10/)
- [iHower - RAG Evaluation](https://ihower.tw/notes/AI-Engineer/Evaluation/RAG+Evaluation)
- [TruLens - AI Quality Education](https://truera.com/ai-quality-education/)
- [TruLens - What is the RAG Triad?](https://truera.com/ai-quality-education/generative-ai-rags/what-is-the-rag-triad/)
- [TruLens - The RAG Triad](https://www.trulens.org/getting_started/core_concepts/rag_triad/)
- [[Building and Evaluating Advanced RAG Applications。建立與評估進階RAG] -RAG Triad of metrics](https://hackmd.io/@YungHuiHsu/H16Y5cdi6)
- [NIST - CVE-2024-5184 Detail](https://nvd.nist.gov/vuln/detail/cve-2024-5184)
- [MITRE ATLAS: The Essential Guide](https://www.nightfall.ai/ai-security-101/mitre-atlas)
- [HuggingFace SF_Convertbot Scanner](https://gist.github.com/rossja/d84a93e5c6b8dd2d4a538aa010b29163)
- [PoisonGPT: How We Hid a Lobotomized LLM on Hugging Face to Spread Fake News](https://blog.mithrilsecurity.io/poisongpt-how-we-hid-a-lobotomized-llm-on-hugging-face-to-spread-fake-news/)
- [Rank-One Model Editing (ROME)](https://rome.baulab.info/)
- [GPU漏洞允許駭客自記憶體汲取資料，殃及蘋果、AMD與高通](https://www.ithome.com.tw/news/160915)